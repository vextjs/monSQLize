/**
 * æ•°æ®å¯¼å‡ºç¤ºä¾‹
 * æ¼”ç¤ºå¦‚ä½•å°†æŸ¥è¯¢ç»“æœå¯¼å‡ºä¸º JSONã€CSV ç­‰æ ¼å¼
 */

const MonSQLize = require('../lib/index');
const fs = require('fs');
const path = require('path');
const { Transform, pipeline } = require('stream');
const { promisify } = require('util');

const pipelineAsync = promisify(pipeline);

async function streamExportExample() {
    console.log('ğŸ“¤ æ•°æ®å¯¼å‡ºç¤ºä¾‹\n');

    const msq = new MonSQLize({
        type: 'mongodb',
        databaseName: 'test',
        config: { uri: 'mongodb://localhost:27017' },
    });

    try {
        const { collection } = await msq.connect();
        console.log('âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ\n');

        const outputDir = path.join(__dirname, 'output');
        if (!fs.existsSync(outputDir)) {
            fs.mkdirSync(outputDir, { recursive: true });
        }

        // ============================================================
        // ç¤ºä¾‹ 1: å¯¼å‡ºä¸º JSONL æ ¼å¼ï¼ˆæ¯è¡Œä¸€ä¸ª JSON å¯¹è±¡ï¼‰
        // ============================================================
        console.log('ç¤ºä¾‹ 1: å¯¼å‡ºä¸º JSONL æ ¼å¼');
        console.log('-'.repeat(60));

        const jsonlTransform = new Transform({
            objectMode: true,
            transform(doc, encoding, callback) {
                // ç§»é™¤ MongoDB çš„ _idï¼Œæˆ–è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                const output = {
                    ...doc,
                    _id: doc._id?.toString()
                };
                this.push(JSON.stringify(output) + '\n');
                callback();
            }
        });

        const jsonlFile = path.join(outputDir, 'orders.jsonl');
        const sourceStream1 = collection('orders').stream({
            query: { status: 'paid' },
            limit: 100
        });

        await pipelineAsync(
            sourceStream1,
            jsonlTransform,
            fs.createWriteStream(jsonlFile)
        );

        console.log(`âœ… æˆåŠŸå¯¼å‡ºåˆ°: ${jsonlFile}\n`);

        // ============================================================
        // ç¤ºä¾‹ 2: å¯¼å‡ºä¸º CSV æ ¼å¼
        // ============================================================
        console.log('ç¤ºä¾‹ 2: å¯¼å‡ºä¸º CSV æ ¼å¼');
        console.log('-'.repeat(60));

        class CSVTransform extends Transform {
            constructor(fields) {
                super({ objectMode: true });
                this.fields = fields;
                this.isFirstRow = true;
            }

            _transform(doc, encoding, callback) {
                if (this.isFirstRow) {
                    // å†™å…¥ CSV å¤´éƒ¨
                    this.push(this.fields.join(',') + '\n');
                    this.isFirstRow = false;
                }

                // å†™å…¥æ•°æ®è¡Œ
                const row = this.fields.map(field => {
                    let value = doc[field];
                    if (value === undefined || value === null) return '';
                    if (value instanceof Date) value = value.toISOString();
                    if (typeof value === 'object') value = JSON.stringify(value);
                    // CSV è½¬ä¹‰ï¼šå¦‚æœåŒ…å«é€—å·ã€å¼•å·æˆ–æ¢è¡Œç¬¦ï¼Œåˆ™ç”¨å¼•å·åŒ…å›´
                    value = String(value);
                    if (value.includes(',') || value.includes('"') || value.includes('\n')) {
                        value = '"' + value.replace(/"/g, '""') + '"';
                    }
                    return value;
                });
                this.push(row.join(',') + '\n');
                callback();
            }
        }

        const csvFile = path.join(outputDir, 'orders.csv');
        const sourceStream2 = collection('orders').stream({
            query: { status: 'paid' },
            projection: { _id: 1, userId: 1, amount: 1, status: 1, createdAt: 1 },
            limit: 100
        });

        const csvTransform = new CSVTransform(['_id', 'userId', 'amount', 'status', 'createdAt']);

        await pipelineAsync(
            sourceStream2,
            csvTransform,
            fs.createWriteStream(csvFile)
        );

        console.log(`âœ… æˆåŠŸå¯¼å‡ºåˆ°: ${csvFile}\n`);

        // ============================================================
        // ç¤ºä¾‹ 3: å¯¼å‡ºä¸º JSON æ•°ç»„æ ¼å¼
        // ============================================================
        console.log('ç¤ºä¾‹ 3: å¯¼å‡ºä¸º JSON æ•°ç»„æ ¼å¼');
        console.log('-'.repeat(60));

        class JSONArrayTransform extends Transform {
            constructor() {
                super({ objectMode: true });
                this.isFirst = true;
            }

            _construct(callback) {
                this.push('[\n');
                callback();
            }

            _transform(doc, encoding, callback) {
                if (!this.isFirst) {
                    this.push(',\n');
                }
                this.isFirst = false;

                const output = {
                    ...doc,
                    _id: doc._id?.toString()
                };
                this.push('  ' + JSON.stringify(output, null, 0));
                callback();
            }

            _flush(callback) {
                this.push('\n]\n');
                callback();
            }
        }

        const jsonFile = path.join(outputDir, 'orders.json');
        const sourceStream3 = collection('orders').stream({
            query: { status: 'paid' },
            limit: 50
        });

        const jsonArrayTransform = new JSONArrayTransform();

        await pipelineAsync(
            sourceStream3,
            jsonArrayTransform,
            fs.createWriteStream(jsonFile)
        );

        console.log(`âœ… æˆåŠŸå¯¼å‡ºåˆ°: ${jsonFile}\n`);

        // ============================================================
        // ç¤ºä¾‹ 4: åˆ†æ‰¹å¯¼å‡ºå¤šä¸ªæ–‡ä»¶
        // ============================================================
        console.log('ç¤ºä¾‹ 4: åˆ†æ‰¹å¯¼å‡ºå¤šä¸ªæ–‡ä»¶');
        console.log('-'.repeat(60));

        const sourceStream4 = collection('orders').stream({
            query: {},
            limit: 100
        });

        let fileIndex = 0;
        let currentBatch = [];
        const batchSize = 20;

        for await (const doc of sourceStream4) {
            currentBatch.push({
                ...doc,
                _id: doc._id?.toString()
            });

            if (currentBatch.length >= batchSize) {
                fileIndex++;
                const batchFile = path.join(outputDir, `orders_batch_${fileIndex}.json`);
                fs.writeFileSync(batchFile, JSON.stringify(currentBatch, null, 2));
                console.log(`  âœ… å¯¼å‡ºæ‰¹æ¬¡ ${fileIndex}: ${currentBatch.length} æ¡è®°å½•`);
                currentBatch = [];
            }
        }

        // å¤„ç†æœ€åä¸€æ‰¹
        if (currentBatch.length > 0) {
            fileIndex++;
            const batchFile = path.join(outputDir, `orders_batch_${fileIndex}.json`);
            fs.writeFileSync(batchFile, JSON.stringify(currentBatch, null, 2));
            console.log(`  âœ… å¯¼å‡ºæ‰¹æ¬¡ ${fileIndex}: ${currentBatch.length} æ¡è®°å½•`);
        }

        console.log(`âœ… å…±å¯¼å‡º ${fileIndex} ä¸ªæ‰¹æ¬¡æ–‡ä»¶\n`);

        console.log('=' .repeat(60));
        console.log('âœ… æ‰€æœ‰ç¤ºä¾‹æ‰§è¡Œå®Œæˆ');
        console.log(`ğŸ“ è¾“å‡ºç›®å½•: ${outputDir}`);
        console.log('=' .repeat(60));

    } catch (error) {
        console.error('âŒ é”™è¯¯:', error.message);
        console.error(error.stack);
        process.exit(1);
    } finally {
        await msq.close();
        console.log('\nâœ… è¿æ¥å·²å…³é—­');
    }
}

// è¿è¡Œç¤ºä¾‹
if (require.main === module) {
    streamExportExample();
}

module.exports = streamExportExample;

